# setup a bridged network for all services to communicate with each other
networks:
  flw-pipeline-network:
    driver: bridge

# going to start up the pipeline backwards... to ensure we have a working pipeline
# starting with the py-pytorch-clf-api service
services:
  py-pytorch-clf-api:
    image: ${ClF_PROJECT_NAME}:latest
    depends_on:
      kafkasetup:
        condition: service_completed_successfully
    networks:
      - flw-pipeline-network
    ports:
      - 8000:8000
  flw-4-postprocessor:
    image: ${PROJECT_NAME_POSTPROCESSOR}:latest
    depends_on:
      kafkasetup:
        condition: service_completed_successfully
    networks:
      - flw-pipeline-network
  flw-3-clf-test-handler:
    image: ${PROJECT_NAME_CLF_TEST_HANDLER}:latest
    depends_on:
      kafkasetup:
        condition: service_completed_successfully
    networks:
      - flw-pipeline-network
  flw-2-preprocessor:
    image: ${PROJECT_NAME_PREPROCESSOR}:latest
    depends_on:
      kafkasetup:
        condition: service_completed_successfully
    networks:
      - flw-pipeline-network
  flw-1-ingestor:
    image: ${PROJECT_NAME_INGESTOR}:latest
    environment:
      - KAFKA_TOPIC_INGESTOR_FROM=${KAFKA_TOPIC_INGESTOR_FROM}
      - KAFKA_TOPIC_INGESTOR_TO=${KAFKA_TOPIC_INGESTOR_TO}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - KAFKA_GROUP_ID=${KAFKA_GROUP_ID}
      - KAFKA_STATS_INTERVAL_MS=${KAFKA_STATS_INTERVAL_MS}
    depends_on:
      kafkasetup:
        condition: service_completed_successfully
    networks:
      - flw-pipeline-network

  flw-0-mock-data-generator:
    image: ${PROJECT_NAME_MOCK_DATA_GENERATOR}:latest
    environment:
      - KAFKA_TOPIC_MOCK_DATA_GENERATOR_TO=${KAFKA_TOPIC_MOCK_DATA_GENERATOR_TO}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - KAFKA_GROUP_ID=${KAFKA_GROUP_ID}
      - KAFKA_STATS_INTERVAL_MS=${KAFKA_STATS_INTERVAL_MS}
    depends_on:
      kafkasetup:
        condition: service_completed_successfully
    networks:
      - flw-pipeline-network

  # install kafka service
  kafka:
    image: bitnami/kafka:latest
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_LOG4J_ROOT_LOGLEVEL=WARN
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - BITNAMI_DEBUG=TRUE
    ports:
      - 9092:9092
    networks:
      - flw-pipeline-network

  kafkasetup:
    image: bitnami/kafka:latest
    depends_on:
      - kafka
    networks:
      - flw-pipeline-network
    restart: "no"
    volumes:
      - type: bind
        source: ./scripts/kafka/create-topics.sh
        target: /create-topics.sh
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - KAFKA_CREATE_TOPICS=${KAFKA_CREATE_TOPICS}
      - BITNAMI_DEBUG=TRUE
    entrypoint: [ "bash", "-c", "/create-topics.sh"]

# install postgres service
  postgres:
    image: postgres:latest
    ports:
      - 5432:5432
    networks:
      - flw-pipeline-network
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
#      - POSTGRES_DB=data_pipeline_db
    volumes:
      # - postgres_data:/var/lib/postgresql/data
      - /tmp/db:/var/lib/postgresql/data
      - ./configs/postgresql/create-db.sql:/docker-entrypoint-initdb.d/create_database.sql
